### Ответы на вопросы по машинному обучению и кибербезопасности

#### 1. Что может использоваться в качестве методов регуляризации?
Регуляризация помогает предотвратить переобучение моделей, добавляя ограничения или штрафы к параметрам модели. Из перечисленных вариантов:

- **Dropout**: Да, это метод регуляризации. Он случайным образом "выключает" часть нейронов во время обучения, что предотвращает излишнюю зависимость модели от конкретных нейронов.
- **L2-регуляризация (Ridge)**: Да, это классический метод регуляризации, который добавляет штраф за большие значения весов модели, уменьшая их влияние.
- **StandardScaler**: Нет, это метод масштабирования данных, а не регуляризации. Он используется для нормализации признаков, чтобы привести их к единому масштабу.
- **EarlyStopping**: Да, это можно считать формой регуляризации, так как ранняя остановка обучения предотвращает переобучение, останавливая процесс, когда ошибка на валидационной выборке перестает уменьшаться.

**Вывод**: Dropout, L2-регуляризация и EarlyStopping являются методами регуляризации.

#### 2. Что характерно для градиентного бустинга?
Градиентный бустинг — это мощный метод ансамблевого обучения, часто используемый в задачах классификации и регрессии. Из перечисленного:

- **Последовательное обучение слабых моделей**: Да, это ключевая характеристика. Градиентный бустинг строит модели (обычно деревья решений) последовательно, где каждая следующая модель исправляет ошибки предыдущей.
- **Использование стохастической оптимизации**: Да, часто используется стохастический градиентный спуск или его вариации для оптимизации функции потерь.
- **Снижение ошибки на каждом шаге**: Да, цель каждой новой модели — минимизировать остаточную ошибку, что является основой метода.
- **Преимущественно применяется к задачам кластеризации**: Нет, градиентный бустинг обычно используется для задач классификации и регрессии, а не кластеризации.

**Вывод**: Характерными чертами являются последовательное обучение, стохастическая оптимизация и снижение ошибки на каждом шаге.

#### 3. Какие библиотеки Python используются для быстрой реализации прототипов в ML?
Для быстрого создания прототипов в машинном обучении важно использовать удобные и мощные инструменты. Из списка:

- **scikit-learn**: Да, это основная библиотека для быстрого прототипирования. Она предоставляет простые API для множества алгоритмов ML.
- **PyTorch**: Да, хотя это библиотека для глубокого обучения, она часто используется для прототипирования благодаря гибкости и простоте экспериментов.
- **TensorFlow**: Да, также используется для глубокого обучения и прототипирования, хотя может быть сложнее для новичков по сравнению с PyTorch.
- **OpenCV (без ML-расширений)**: Нет, OpenCV в основном используется для обработки изображений и видео, а не для машинного обучения как такового.

**Вывод**: scikit-learn, PyTorch и TensorFlow подходят для быстрого прототипирования в ML.

#### 4. Что из перечисленного может улучшить обобщающую способность нейронной сети?
Обобщающая способность — это способность модели хорошо работать на новых данных. Из вариантов:

- **Batch Normalization**: Да, этот метод нормализует входные данные для каждого слоя, что ускоряет обучение и улучшает обобщение.
- **Увеличение числа параметров модели**: Нет, увеличение числа параметров часто приводит к переобучению, особенно если данных недостаточно.
- **Data Augmentation**: Да, аугментация данных (например, повороты, изменения яркости изображений) увеличивает разнообразие данных и помогает модели лучше обобщать.
- **Dropout**: Да, как упоминалось ранее, Dropout предотвращает переобучение, улучшая обобщающую способность.

**Вывод**: Batch Normalization, Data Augmentation и Dropout способствуют улучшению обобщающей способности.

#### 5. Какой метрике стоит отдать предпочтение при дисбалансе классов?
При дисбалансе классов важно выбирать метрику, которая учитывает неравномерное распределение данных. Из списка:

- **Accuracy**: Нет, точность может быть обманчивой при дисбалансе, так как модель может просто предсказывать преобладающий класс.
- **MAE**: Нет, средняя абсолютная ошибка обычно используется в задачах регрессии, а не классификации.
- **ROC-AUC**: Да, эта метрика учитывает баланс между истинно положительными и ложно положительными результатами, но может быть менее информативной при сильном дисбалансе.
- **F1-score**: Да, это лучшая метрика при дисбалансе, так как она учитывает как точность (precision), так и полноту (recall), давая сбалансированную оценку.

**Вывод**: Предпочтение стоит отдать F1-score при дисбалансе классов.

#### 6. Какие признаки могут свидетельствовать о наличии утечек (data leakage)?
Утечка данных — это ситуация, когда модель получает доступ к информации, которая не должна быть доступна на этапе обучения. Из списка:

- **Подозрительно высокая точность модели**: Да, это может быть признаком утечки, особенно если результаты кажутся нереалистичными.
- **Использование target-переменной в признаках**: Да, это классический пример утечки, так как модель получает прямой доступ к целевой переменной.
- **Использование случайного seed при разделении**: Нет, использование seed само по себе не вызывает утечку, это просто способ воспроизводимости.
- **Совпадение распределений в train/test**: Нет, совпадение распределений желательно, чтобы данные были репрезентативными, это не признак утечки.

**Вывод**: Подозрительно высокая точность и использование target-переменной в признаках указывают на утечку данных.

#### 7. Что может быть источником обучающих данных в задачах анализа инцидентов?
Для анализа инцидентов в кибербезопасности важно использовать релевантные данные. Из списка:

- **PCAP-файлы с метками активности**: Да, это ценный источник данных, так как они содержат сетевой трафик с информацией о действиях.
- **Sysmon-логи**: Да, эти логи предоставляют детальную информацию о действиях в системе, что полезно для анализа инцидентов.
- **Образцы вредоносного кода**: Да, они могут быть использованы для обучения моделей на выявление вредоносных программ.
- **Физическая топология ЛВС**: Нет, это скорее статическая информация, которая не содержит данных о поведении или инцидентах.

**Вывод**: PCAP-файлы, Sysmon-логи и образцы вредоносного кода являются источниками данных для анализа инцидентов.

#### 8. Какие подходы применимы к детектированию атак "нулевого дня"?
Атаки "нулевого дня" — это угрозы, для которых еще нет сигнатур. Из списка:

- **Обнаружение по сигнатурам**: Нет, этот метод не работает для атак "нулевого дня", так как сигнатур еще не существует.
- **Обнаружение аномалий на основе поведенческого анализа**: Да, это эффективный подход, так как он фокусируется на отклонениях от нормального поведения.
- **Семантический анализ системных вызовов**: Да, анализ системных вызовов может выявить необычные паттерны, связанные с новыми атаками.
- **Autoencoder-ы и unsupervised модели**: Да, эти методы могут обнаруживать аномалии без необходимости размеченных данных.

**Вывод**: Подходы, основанные на аномалиях, семантическом анализе и unsupervised моделях, применимы для атак "нулевого дня".

#### 9. Какие методы используются при генерации adversarial attacks?
Adversarial атаки создают примеры, которые обманывают модели машинного обучения. Из списка:

- **FGSM (Fast Gradient Sign Method)**: Да, это один из базовых методов для создания adversarial примеров.
- **PGD (Projected Gradient Descent)**: Да, это более продвинутый метод, который использует итеративный подход для создания атак.
- **PCA**: Нет, это метод снижения размерности, а не генерации атак.
- **Carlini & Wagner (C&W)**: Да, это мощный метод, который создает минимальные изменения для обмана модели.

**Вывод**: FGSM, PGD и C&W используются для генерации adversarial атак.

#### 10. Какие типы сетевых данных наиболее чувствительны к аномалиям?
Аномалии в сетевых данных могут указывать на угрозы или сбои. Из списка:

- **DNS-запросы**: Да, необычные DNS-запросы могут указывать на вредоносную активность, например, C2-коммуникацию.
- **MAC-адреса узлов**: Нет, MAC-адреса сами по себе редко связаны с аномалиями, так как они статичны.
- **Объём и частота трафика**: Да, резкие изменения в трафике часто свидетельствуют о проблемах, таких как DDoS-атаки.
- **Используемые порты и протоколы**: Да, использование нестандартных портов или протоколов может быть признаком аномалии.

**Вывод**: DNS-запросы, объём и частота трафика, а также порты и протоколы чувствительны к аномалиям.

#### 11. Какие направления наиболее актуальны в R&D по кибербезопасности с использованием ИИ?
Исследования и разработки в области ИИ для кибербезопасности фокусируются на решении сложных задач. Из списка:

- **Обучение на неразмеченных данных (self-supervised)**: Да, это актуально, так как размеченные данные в кибербезопасности часто недоступны.
- **Объяснимый ИИ (XAI) для безопасности**: Да, понимание решений ИИ критически важно для доверия в задачах безопасности.
- **Устойчивость к adversarial attacks**: Да, защита моделей от атак — одно из ключевых направлений.
- **Автоматизация Wi-Fi аудита**: Нет, это более узкая и менее приоритетная задача по сравнению с другими направлениями.

**Вывод**: Актуальными направлениями являются обучение на неразмеченных данных, объяснимый ИИ и устойчивость к adversarial атакам.
